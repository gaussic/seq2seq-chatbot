{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from masked_cross_entropy import masked_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/twitter'\n",
    "train_dir = os.path.join(base_dir, 'twitter_clean.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'twitter_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    \"\"\"\n",
    "    ÊñáÊú¨È¢ÑÂ§ÑÁêÜÔºåËé∑ÂèñËØçÊ±áË°®ÔºåÂπ∂Â∞ÜÂ≠óÁ¨¶‰∏≤ÊñáÊú¨ËΩ¨Êç¢‰∏∫Êï∞Â≠óÂ∫èÂàó„ÄÇ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_dir, vocab_dir):\n",
    "        assert os.path.exists(train_dir), 'File %s does not exist.' % train_dir\n",
    "        assert os.path.exists(vocab_dir), 'File %s does not exist.' % vocab_dir\n",
    "\n",
    "        words = open(vocab_dir, encoding='utf-8').read().strip().split('\\n')\n",
    "        word_to_id = dict(zip(words, range(len(words))))\n",
    "        \n",
    "        assert word_to_id['<pad>'] == 0, \"<pad> id should be 0.\"\n",
    "        \n",
    "        self.words = words\n",
    "        self.word_to_id = word_to_id\n",
    "        \n",
    "        self.tokenize(train_dir)\n",
    "        \n",
    "    def tokenize(self, train_dir):\n",
    "        data = open(train_dir, encoding='utf-8').read().strip().split('\\n')\n",
    "        questions, answers = [], []\n",
    "        for line in data:\n",
    "            question, answer = line.split(\" ==> \")\n",
    "            questions.append(self.text_to_ids(question))\n",
    "            answers.append(self.text_to_ids(answer))\n",
    "            \n",
    "        total_num = len(questions)\n",
    "        train_num = int(0.9 * total_num)\n",
    "        self.x_train, self.y_train = questions[:train_num], answers[:train_num]\n",
    "        self.x_test, self.y_test = questions[train_num:], answers[train_num:]\n",
    "        \n",
    "    def text_to_ids(self, text):\n",
    "        return [self.word_to_id[x] for x in (text.split() + ['<eos>'])]\n",
    "    \n",
    "    def ids_to_text(self, ids):\n",
    "        return [self.words[x] for x in ids]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Train length: %d, Test length: %d, Vocabulary size: %d\" % (len(self.x_train), \n",
    "                                                                           len(self.x_test), \n",
    "                                                                           len(self.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Corpus' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-ef419a80e5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Corpus' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train length: 194785, Test length: 21643, Vocabulary size: 10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(train_dir, vocab_dir)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, data, labels, batch_size=64):\n",
    "        num_batches = len(data) // batch_size\n",
    "        data, labels = data[:(num_batches * batch_size)], labels[:(num_batches * batch_size)]\n",
    "        self.data = []\n",
    "        for i in range(num_batches):\n",
    "            x_batch = data[(i * batch_size):((i+1)*batch_size)]\n",
    "            y_batch = labels[(i * batch_size):((i+1)*batch_size)]\n",
    "            x_pad, x_lengths, y_pad, y_lengths = self.pad_batch(x_batch, y_batch)\n",
    "            self.data.append((x_pad, x_lengths, y_pad, y_lengths))\n",
    "            \n",
    "    def pad_batch(self, x_batch, y_batch):\n",
    "        seq_pairs = sorted(zip(x_batch, y_batch), key=lambda p: len(p[0]), reverse=True)\n",
    "        x_batch, y_batch = zip(*seq_pairs)\n",
    "        \n",
    "        x_lengths = list(map(len, x_batch))\n",
    "        x_padded = [self.pad_seq(s, max(x_lengths)) for s in x_batch]\n",
    "        \n",
    "        y_lengths = list(map(len, y_batch))\n",
    "        y_padded = [self.pad_seq(s, max(y_lengths)) for s in y_batch]\n",
    "        \n",
    "        input_var = Variable(torch.LongTensor(x_padded)).transpose(0, 1)\n",
    "        target_var = Variable(torch.LongTensor(y_padded)).transpose(0, 1)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_var = input_var.cuda()\n",
    "            target_var = target_var.cuda()\n",
    "            \n",
    "        return input_var, x_lengths, target_var, y_lengths\n",
    "    \n",
    "    def pad_seq(self, seq, max_len):\n",
    "        return seq + [0] * (max_len - len(seq))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data = DataSet(corpus.x_train, corpus.y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad, x_lengths, y_pad, y_lengths = random.choice(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    3    26   354  ...    294     3   102\n",
       "   27   441   414  ...      3   574  2750\n",
       "    3     8   337  ...     12   100     2\n",
       "       ...          ‚ã±          ...       \n",
       " 6293   295    12  ...      0     0     0\n",
       "  120     6     2  ...      0     0     0\n",
       "    2     2     0  ...      0     0     0\n",
       "[torch.LongTensor of size 21x64]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(10000, 128)\n",
       "  (gru): GRU(128, 128, dropout=0.1)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10000, 128)\n",
    "encoder_test = EncoderRNN(10000, 128, embedding)\n",
    "encoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_hidden = encoder_test(x_pad, x_lengths, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "  0.0967  0.0174 -0.1583  ...   0.1991 -0.1848 -0.3645\n",
       "  0.3320 -0.1663 -0.0866  ...  -0.3093  0.3217  0.3075\n",
       " -0.3506  0.0435  0.1432  ...   0.0499 -0.3180 -0.2288\n",
       "           ...             ‚ã±             ...          \n",
       "  0.0418 -0.1770  0.2808  ...   0.3639 -0.3336  0.1129\n",
       "  0.0967  0.0174 -0.1583  ...   0.1991 -0.1848 -0.3645\n",
       "  0.3248  0.0684 -0.0827  ...  -0.0618 -0.2805 -0.2774\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  0.0791  0.0415  0.1415  ...  -0.3874 -0.1195 -0.5748\n",
       "  0.3152  0.1634  0.3865  ...  -0.3589  0.4808 -0.4656\n",
       " -0.2568 -0.3121 -0.1265  ...   0.3454  0.2699 -0.2856\n",
       "           ...             ‚ã±             ...          \n",
       "  0.0958 -0.0335  0.0219  ...   0.4159 -0.2700 -0.3298\n",
       " -0.0577 -0.0062 -0.2672  ...  -0.1798 -0.3036 -0.4636\n",
       " -0.1150  0.3221 -0.2650  ...  -0.3449 -0.0219 -0.1261\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  0.1644  0.0734 -0.0544  ...  -0.0364 -0.2185 -0.5937\n",
       "  0.3672  0.1820  0.2226  ...  -0.1956 -0.1193 -0.5428\n",
       " -0.0770  0.0233 -0.3029  ...   0.3143 -0.0126 -0.3889\n",
       "           ...             ‚ã±             ...          \n",
       "  0.1316 -0.1074  0.6446  ...  -0.2793 -0.0285  0.0554\n",
       " -0.1491  0.0441 -0.3193  ...   0.0704 -0.0144 -0.3767\n",
       " -0.2554  0.2597 -0.3478  ...  -0.3054  0.1132 -0.0572\n",
       "... \n",
       "\n",
       "(18 ,.,.) = \n",
       "  0.2014 -0.0956  0.2507  ...   0.1866  0.1324  0.1914\n",
       " -0.0231  0.5715  0.0258  ...  -0.0282  0.3408 -0.3214\n",
       " -0.0101  0.1410  0.5668  ...  -0.6094 -0.2643  0.1359\n",
       "           ...             ‚ã±             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "\n",
       "(19 ,.,.) = \n",
       "  0.2861 -0.3034 -0.2020  ...  -0.3753  0.3523 -0.0519\n",
       "  0.2026  0.5224  0.2180  ...  -0.0899  0.5556 -0.4467\n",
       " -0.2277  0.1092  0.0964  ...  -0.5213 -0.1181  0.1329\n",
       "           ...             ‚ã±             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "\n",
       "(20 ,.,.) = \n",
       " -0.0087 -0.1409 -0.2874  ...  -0.3458  0.3274  0.0193\n",
       " -0.1047  0.3789 -0.0794  ...  -0.1094  0.3597 -0.2429\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ‚ã±             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 21x64x128]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       " -8.6541e-03 -1.4094e-01 -2.8744e-01  ...  -3.4583e-01  3.2744e-01  1.9311e-02\n",
       " -1.0469e-01  3.7888e-01 -7.9401e-02  ...  -1.0945e-01  3.5973e-01 -2.4294e-01\n",
       " -2.2767e-01  1.0918e-01  9.6437e-02  ...  -5.2132e-01 -1.1806e-01  1.3289e-01\n",
       "                 ...                   ‚ã±                   ...                \n",
       " -8.3465e-02 -4.5670e-02  1.3540e-01  ...  -2.8234e-01  8.8925e-02  3.5188e-02\n",
       " -3.1121e-01  1.0943e-01 -3.9635e-01  ...  -3.6520e-02  1.2125e-01 -1.9541e-01\n",
       " -2.5543e-01  2.5967e-01 -3.4784e-01  ...  -3.0540e-01  1.1317e-01 -5.7166e-02\n",
       "[torch.FloatTensor of size 1x64x128]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(rnn_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embedding): Embedding(10000, 128)\n",
       "  (embedding_dropout): Dropout(p=0.1)\n",
       "  (gru): GRU(128, 128, dropout=0.1)\n",
       "  (out): Linear(in_features=128, out_features=10000)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_test = DecoderRNN(128, 10000, embedding)\n",
    "decoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_target_length = max(y_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Variable(torch.LongTensor([corpus.word_to_id['<sos>']] * batch_size))\n",
    "decoder_hidden = encoder_hidden[:decoder_test.n_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       " -8.6541e-03 -1.4094e-01 -2.8744e-01  ...  -3.4583e-01  3.2744e-01  1.9311e-02\n",
       " -1.0469e-01  3.7888e-01 -7.9401e-02  ...  -1.0945e-01  3.5973e-01 -2.4294e-01\n",
       " -2.2767e-01  1.0918e-01  9.6437e-02  ...  -5.2132e-01 -1.1806e-01  1.3289e-01\n",
       "                 ...                   ‚ã±                   ...                \n",
       " -8.3465e-02 -4.5670e-02  1.3540e-01  ...  -2.8234e-01  8.8925e-02  3.5188e-02\n",
       " -3.1121e-01  1.0943e-01 -3.9635e-01  ...  -3.6520e-02  1.2125e-01 -1.9541e-01\n",
       " -2.5543e-01  2.5967e-01 -3.4784e-01  ...  -3.0540e-01  1.1317e-01 -5.7166e-02\n",
       "[torch.FloatTensor of size 1x64x128]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder_test.output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "    decoder_input = decoder_input.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through decoder one time step at a time\n",
    "for t in range(max_target_length):\n",
    "    decoder_output, decoder_hidden = decoder_test(\n",
    "        decoder_input, decoder_hidden\n",
    "    )\n",
    "    all_decoder_outputs[t] = decoder_output # Store this step's outputs\n",
    "    decoder_input = y_pad[t] # Next input is current target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 9.22211742401123\n"
     ]
    }
   ],
   "source": [
    "loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    y_pad.transpose(0, 1).contiguous(),\n",
    "    y_lengths, \n",
    "    USE_CUDA\n",
    ")\n",
    "print('loss', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([corpus.word_to_id['<sos>']] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths,\n",
    "        USE_CUDA\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15988\n",
      "bruh this whole time i've been looking for a plug while i had a <unk> charger in my bag üòë <eos>\n",
      "but if you're looking for a real plug it my line <eos>\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(len(corpus.x_test)))\n",
    "print(index)\n",
    "input_seq, target_seq = corpus.x_test[index], corpus.y_test[index]\n",
    "print(' '.join(corpus.ids_to_text(input_seq)))\n",
    "print(' '.join(corpus.ids_to_text(target_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    index = random.choice(range(len(corpus.x_test)))\n",
    "    input_seq, target_seq = corpus.x_test[index], corpus.y_test[index]\n",
    "    output_words = evaluate(input_seq)\n",
    "    print(\"Input:\", ' '.join(corpus.ids_to_text(input_seq)))\n",
    "    print(\"Target:\", ' '.join(corpus.ids_to_text(target_seq)))\n",
    "    print(\"Predicted:\", ' '.join(output_words))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ( video ) high school <unk> from florida turns all the way up for homecoming - <eos>\n",
      "Target: support and retweet <eos>\n",
      "Predicted: <unk> <unk> <unk> . <eos>\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(input_seq, max_length=20):\n",
    "    input_lengths = [len(input_seq)]\n",
    "    input_batches = Variable(torch.LongTensor([input_seq]), volatile=True).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "        \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([corpus.word_to_id['<sos>']]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_words = []\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden\n",
    "        )\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == corpus.word_to_id['<eos>']:\n",
    "            decoded_words.append('<eos>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(corpus.words[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 50\n",
    "\n",
    "train_data = DataSet(corpus.x_train, corpus.y_train, batch_size)\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 50000\n",
    "epoch = 0\n",
    "plot_every = 20\n",
    "print_every = 2\n",
    "evaluate_every = 10\n",
    "\n",
    "vocab_size = len(corpus.words)\n",
    "embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(vocab_size, hidden_size, embedding, n_layers, dropout=dropout)\n",
    "decoder = DecoderRNN(hidden_size, vocab_size, embedding, n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 5s (- 2428m 18s) (2 0%) 9.1916\n",
      "0m 10s (- 2261m 46s) (4 0%) 9.0860\n",
      "0m 17s (- 2378m 54s) (6 0%) 8.9007\n",
      "0m 22s (- 2362m 18s) (8 0%) 8.4297\n",
      "0m 27s (- 2312m 44s) (10 0%) 7.6483\n",
      "Input: funny how he has a phd and you don't <eos>\n",
      "Target: uhh first of all i put the wrong teachers name down that's my fault <eos>\n",
      "Predicted: <unk> <eos>\n",
      "0m 32s (- 2276m 48s) (12 0%) 6.9668\n",
      "0m 37s (- 2243m 0s) (14 0%) 6.6498\n"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random.choice(train_data)\n",
    "\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer\n",
    "    )\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "    \n",
    "    # job.record(epoch, loss)\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch % evaluate_every == 0:\n",
    "        evaluate_randomly()\n",
    "\n",
    "#     if epoch % plot_every == 0:\n",
    "#         plot_loss_avg = plot_loss_total / plot_every\n",
    "#         plot_losses.append(plot_loss_avg)\n",
    "#         plot_loss_total = 0\n",
    "        \n",
    "#         # TODO: Running average helper\n",
    "#         ecs.append(eca / plot_every)\n",
    "#         dcs.append(dca / plot_every)\n",
    "#         ecs_win = 'encoder grad (%s)' % hostname\n",
    "#         dcs_win = 'decoder grad (%s)' % hostname\n",
    "#         vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n",
    "#         vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n",
    "#         eca = 0\n",
    "#         dca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
