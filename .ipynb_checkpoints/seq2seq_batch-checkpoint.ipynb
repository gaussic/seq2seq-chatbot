{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/twitter'\n",
    "train_dir = os.path.join(base_dir, 'twitter_clean.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'twitter_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    \"\"\"\n",
    "    文本预处理，获取词汇表，并将字符串文本转换为数字序列。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_dir, vocab_dir):\n",
    "        assert os.path.exists(train_dir), 'File %s does not exist.' % train_dir\n",
    "        assert os.path.exists(vocab_dir), 'File %s does not exist.' % vocab_dir\n",
    "\n",
    "        words = open(vocab_dir, encoding='utf-8').read().strip().split('\\n')\n",
    "        word_to_id = dict(zip(words, range(len(words))))\n",
    "        \n",
    "        assert word_to_id['<pad>'] == 0, \"<pad> id should be 0.\"\n",
    "        \n",
    "        self.words = words\n",
    "        self.word_to_id = word_to_id\n",
    "        \n",
    "        self.tokenize(train_dir)\n",
    "        \n",
    "    def tokenize(self, train_dir):\n",
    "        data = open(train_dir, encoding='utf-8').read().strip().split('\\n')\n",
    "        questions, answers = [], []\n",
    "        for line in data:\n",
    "            question, answer = line.split(\" ==> \")\n",
    "            questions.append(self.text_to_ids(question))\n",
    "            answers.append(self.text_to_ids(answer))\n",
    "            \n",
    "        total_num = len(questions)\n",
    "        train_num = int(0.9 * total_num)\n",
    "        self.x_train, self.y_train = questions[:train_num], answers[:train_num]\n",
    "        self.x_test, self.y_test = questions[train_num:], answers[train_num:]\n",
    "        \n",
    "    def text_to_ids(self, text):\n",
    "        return [self.word_to_id[x] for x in (text.split() + ['<eos>'])]\n",
    "    \n",
    "    def ids_to_text(self, ids):\n",
    "        return [self.words[x] for x in ids]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Train length: %d, Test length: %d, Vocabulary size: %d\" % (len(self.x_train), \n",
    "                                                                           len(self.x_test), \n",
    "                                                                           len(self.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(train_dir, vocab_dir)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, data, labels, batch_size=64):\n",
    "        num_batches = len(data) // batch_size\n",
    "        data, labels = data[:(num_batches * batch_size)], labels[:(num_batches * batch_size)]\n",
    "        self.x, self.y = [], []\n",
    "        for i in range(num_batches):\n",
    "            x_batch = data[(i * batch_size):((i+1)*batch_size)]\n",
    "            y_batch = labels[(i * batch_size):((i+1)*batch_size)]\n",
    "            x_pad, y_pad = self.pad_batch(x_batch, y_batch)\n",
    "            self.x.append(x_pad)\n",
    "            self.y.append(y_pad)\n",
    "            \n",
    "    def pad_batch(self, x_batch, y_batch):\n",
    "        seq_pairs = sorted(zip(x_batch, y_batch), key=lambda p: len(p[0]), reverse=True)\n",
    "        x_batch, y_batch = zip(*seq_pairs)\n",
    "        \n",
    "        x_maxlen = max(map(len, x_batch))\n",
    "        x_pad = [self.pad_seq(s, x_maxlen) for s in x_batch]\n",
    "        \n",
    "        y_maxlen = max(map(len, y_batch))\n",
    "        y_pad = [self.pad_seq(s, y_maxlen) for s in y_batch]\n",
    "        \n",
    "        input_var = Variable(torch.LongTensor(x_pad)).transpose(0, 1)\n",
    "        target_var = Variable(torch.LongTensor(y_pad)).transpose(0, 1)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_var = input_var.cuda()\n",
    "            target_var = target_var.cuda()\n",
    "        return input_var, target_var\n",
    "    \n",
    "    def pad_seq(self, seq, max_len):\n",
    "        return seq + [0] * (max_len - len(seq))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataSet(corpus.x_train, corpus.y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ trump's ] ability to repeat false statements with seemingly few consequences has become a point of political ... <eos>\n",
      "<unk> : since <unk> 15 . 91 % od trumps statements are false . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "losing 5 straight to braves is <unk> ? can it just be they are in mets head ? <eos> <pad>\n",
      "they haven't lost 5 straight to atlanta . they just took 2 out of 3 at turner . <eos> <pad> <pad>\n",
      "\n",
      "dear trump supporters , when did murdering innocent civilians become \" american \" ? yours truly , <eos> <pad> <pad>\n",
      "oh lord , don't ask <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "<unk> power <unk> rose pak <unk> lived the life of her choosing <unk> by brings back memories <eos> <pad> <pad>\n",
      ". my mom went to college with rose pak . here's how she looked in <unk> <eos> <pad> <pad> <pad> <pad>\n",
      "\n",
      "dear trump supporters , when did murdering innocent civilians become \" american \" ? yours truly , <eos> <pad> <pad>\n",
      "... i think you mean when did we * admit * that murdering innocent civilians is \" american \" <unk> <eos>\n",
      "\n",
      "my family of 3 <unk> flies for under $ 500 r / t . lucky spot . <eos> <pad> <pad>\n",
      "that's insane ! ! ! <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "donald trump jr . steps in it again ( and again ) via <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "he would have been great at training the hitler youth . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "mets miss playoffs there is zero way mets can bring terry back <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "ive said that for a few months . but they still might . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "who faces freeman then ? <unk> ? <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "of course . go by the book , win with the best soldiers on the field . <eos> <pad> <pad> <pad>\n",
      "\n",
      "exclusive look at ps4 version . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "... i have a pc so dont know what point you <unk> <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rnd, y_rnd = random.choice(train_data)\n",
    "for i in range(10):\n",
    "    print(' '.join(corpus.ids_to_text(x_rnd[:, i].data.numpy())))\n",
    "    print(' '.join(corpus.ids_to_text(y_rnd[:, i].data.numpy())))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
